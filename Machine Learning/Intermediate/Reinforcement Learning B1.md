# Reinforcement Learning B1
Basic knowledge of reinforcement learning.

## Topics
1.	Multi-armed Bandits 
2.	Finite Markov Decision Process
3.	Dynamic Programming

## Bibliography
1. Sutton, Richard S, and Andrew G. Barto. **Introduction to Reinforcement Learning**. 2nd Edition, MIT Press Cambridge, 2018.  Chapters 1, 2, 3, and 4.
2. Kochenderfer, Mykel J. **Decision Making Under Uncertainty: Theory and Application**, MIT press, 2015. Chapters 3 and 4.

## Evaluation
70% Written test and 30% Programming project.

## Online Courses
1. [David Silver. Reinforcement Learning 2015.](http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html)
2. [DeepMind. Reinforcement Learning 2018.](https://www.youtube.com/playlist?list=PLqYmG7hTraZDNJre23vqCGIVpfZ_K2RZs)
3. [Bertsekas. Reinforcement Learning and Optimal Control, ASU-2019](http://web.mit.edu/dimitrib/www/RLbook.html)

## Secondary Bibliography
1. Lattimore, Tor, and Csaba Szepesvari. **Bandit Algorithms**, Cambridge University Press (preprint), 2019. 
   **_Notes_**: _Chapter 7 contains the proof that the UCB rule achieves a sublinear regret. The book in general contains many rigorous results about bandits._ 
2. Dimitri P. Bertsekas, **Reinforcement Learning and Optimal Control**, Athena Scientific, 2019.
3. Hunter, J K, and B Nachtergaele. **Applied Analysis**, World Scientific, 2001. 
   **_Notes_**: _Chapter 3 contains the proof of Contraction Mapping Theorem. Which is the theoretical tool used to prove the convergence of various RL iterative algorithms_. 

## Code
1. [Python implementation of the examples in Sutton's book](https://github.com/ShangtongZhang/reinforcement-learning-an-introduction)
2. [OpenAI Gym](https://gym.openai.com)

